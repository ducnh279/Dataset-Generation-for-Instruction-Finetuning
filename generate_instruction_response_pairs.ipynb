{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxMxDwQAGO5w"
   },
   "source": [
    "# Generate Instruction-Response Pairs\n",
    "\n",
    "- This notebook uses Phi-3 3.8B parameters instruct model to generate a synthetic dataset.\n",
    "\n",
    "- The dataset creation follows the \"hack\" proposed in the paper \"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing\": https://arxiv.org/abs/2406.08464\n",
    "\n",
    "- The dataset creation includes 2 steps:\n",
    "    - Step 1: Instruction generation\n",
    "    - Step 2: Response generation\n",
    "\n",
    "- The generated dataset will be an instruction dataset with \"instruction\" and \"output\" fields, similar to what can be found in Alpaca:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"instruction\": \"What is the capital of Vietnam?\",\n",
    "    \"output\": \"The capital of Vietnam is Hanoi.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUQMwXjcL9IX"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0Ze_1UL_68hS"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lIYdn1woOS1n"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYk4z8K5MALK"
   },
   "source": [
    "# Load Tokenizer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IfXVnlKaMKeC"
   },
   "outputs": [],
   "source": [
    "model_id = 'microsoft/Phi-3-mini-128k-instruct'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "referenced_widgets": [
      "e095a60c04e44fe1a389c5231cbb5acd",
      "af873eddff054a62b6cae6c16212cb61",
      "e4ac157ccbea408a9280b8621200b1a5",
      "d16c92d8e2eb465292ad69f8ad0cb6be",
      "f8e6ae664a98459f94704cc6a0495338",
      "3f8ef86f775643ef9ff60e11a82d7994",
      "9eb4878622cc4162b8e590be415c28be",
      "1f52bb95d9b44033a984205adc69b2a9",
      "3d4a782358af4a2abdf677aa404a9831",
      "535b15377b3a44f1846b29ae9391e0ac",
      "99d2d17c166d484198e8f1b109c3de33"
     ]
    },
    "id": "RO-713DY60GS",
    "outputId": "f154e9a9-b8b3-4008-f343-82742d533b47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e095a60c04e44fe1a389c5231cbb5acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             device_map=device,\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                             torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To1EtgFbMZPu"
   },
   "source": [
    "# Examine phi-3 chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lvZvtNxk7gJG"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': 'What is the capital of Vietnam?'},\n",
    "    {'role': 'assistant', 'content': 'The capital of Vietnam is Hanoi.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LGjhyfwj9bOt",
    "outputId": "897ba6d1-3622-4652-f677-1e80e223b4a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<s><|user|> What is the capital of Vietnam?<|end|><|assistant|> The capital of Vietnam is Hanoi.<|end|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    tokenizer.apply_chat_template(messages)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-BcQhvOMmxW"
   },
   "source": [
    "# Step 1: Instruction Generation\n",
    "\n",
    "With the chat template below, to generate an instruction, we only need to pass the input as `<s>|user|` and set a stop criterion as `|end|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNlGooX4QcoR",
    "outputId": "965f4b97-f5a4-458e-957d-2b7bab237de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32007]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('<|end|>', add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1orNZJv8Qlbf"
   },
   "outputs": [],
   "source": [
    "stop_on_tokens = [32007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LUo_37QRBMiM"
   },
   "outputs": [],
   "source": [
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [32007]\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ulQAf0CrANY7"
   },
   "outputs": [],
   "source": [
    "def generate_instruction(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        pre_query_template,\n",
    "        stopping_criteria,\n",
    "        device\n",
    "    ):\n",
    "    encodings = tokenizer(pre_query_template, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "\n",
    "    tokens = model.generate(\n",
    "        input_ids=encodings['input_ids'],\n",
    "        max_new_tokens=1024,\n",
    "        temperature=1.,\n",
    "        top_p=1.,\n",
    "        do_sample=True,\n",
    "        stopping_criteria=stopping_criteria,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )[0]\n",
    "\n",
    "    instruction = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UobMPh76BCO9",
    "outputId": "2b751ca5-905c-4a37-9359-db45a87133a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated instruction: I need your help to construct a PowerShell script with a function named 'Get-CMSLogonUser' that fetches a list of current logon users from a Citrix management platform. I require the function to have optional input parameters: an identifier and a filter, along with several output parameters like page size, page number, all defaulting to 50 and 1 respectively. There also should be an 'Auth' object that I'll pass to it.\n",
      "\n",
      "The function needs to use an API call to obtain the user list, which involves constructing the URL with the required parameters and performing an API request. It should handle the response and output the data.\n",
      "\n",
      "Could you improve this initial outline of the script?\n",
      "\n",
      "```powershell\n",
      "function Get-CMSLogonUser {\n",
      "    param (\n",
      "        [int]$Identifier = 0,\n",
      "        [string]$Filter = \"\",\n",
      "        [int]$PageSize = 50,\n",
      "        [int]$PageNumber = 1\n",
      "    )\n",
      "\n",
      "    # Assuming $authObject exists and contains necessary auth info\n",
      "\n",
      "    $url = \"/api/v1/citrix/vnp/users/search?filter=$Filter&pageSize=$PageSize&pageNumber=$PageNumber&identifier=$Identifier\"\n",
      "    # API call should be made here using $authObject\n",
      "    # Response should be returned and processed\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction = generate_instruction(model=model,\n",
    "                     tokenizer=tokenizer,\n",
    "                     pre_query_template='<s><|user|>',\n",
    "                     stopping_criteria=stopping_criteria,\n",
    "                     device=device)\n",
    "\n",
    "print(f'Generated instruction: {instruction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn755U7MTMzC"
   },
   "source": [
    "# Step 2: Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jBSm3X6nBHif"
   },
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, instruction, device):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': instruction}\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    tokens = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=1.,\n",
    "        top_p=1.,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )[0]\n",
    "    instruction_and_response = tokenizer.decode(tokens)\n",
    "    response = instruction_and_response.split('<|assistant|>')[-1][:-len('<|end|>')]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVx15TNeTqky",
    "outputId": "c647f831-4f8b-4835-e128-50f737177a34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response:  Understood. Here is a snippet of the refactored Python class incorporating the changes:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from enum import Enum\n",
      "\n",
      "class PageSize(Enum):\n",
      "    FIRST = 1\n",
      "    DEFAULT = 50\n",
      "    LAST = 100\n",
      "\n",
      "class PageNumber(Enum):\n",
      "    FIRST = 1\n",
      "\n",
      "class AuthError(Exception):\n",
      "    pass\n",
      "\n",
      "class CMSResponse:\n",
      "    def __init__(self, status_code, data):\n",
      "        self.status_code = status_code\n",
      "        self.data = data\n",
      "\n",
      "class CMSAuth:\n",
      "    def __init__(self, client_id, client_secret):\n",
      "        self.client_id = client_id\n",
      "        self.client_secret = client_secret\n",
      "        # Additional security-related fields could be added here\n",
      "\n",
      "    def perform_api_call(self, auth_token, payload):\n",
      "        # Example of OAuth2 request - this may vary to fit exact OAuth2 setup\n",
      "        headers = {'Authorization': f'Bearer {auth_token}'}\n",
      "        url = 'https://api.example.com/citrix'\n",
      "        response = requests.post(url, json=payload, headers=headers)\n",
      "        if response.status_code != 200:\n",
      "            raise AuthError(f\"Auth failed with status code: {response.status_code}\")\n",
      "        return response.json()\n",
      "\n",
      "class LogonUserRetriever:\n",
      "    def __init__(self, auth):\n",
      "        self.auth = auth\n",
      "\n",
      "    def _get_data(self, filter, identifier, page_size=PageSize.DEFAULT.value, page_number=PageNumber.FIRST.value):\n",
      "        payload = {\n",
      "            'filter': filter,\n",
      "            'pageSize': page_size,\n",
      "            'pageNumber': page_number,\n",
      "            'identifier': identifier\n",
      "        }\n",
      "        return self.auth.perform_api_call(auth_token=\"YOUR_AUTH_TOKEN_HERE\", payload=payload)\n",
      "\n",
      "    def get_logon_users(self, filter='', identifier=0):\n",
      "        if not filter:\n",
      "            raise ValueError(\"Filter must be provided\")\n",
      "        result = self._get_data(filter=filter, identifier=identifier)\n",
      "        return result\n",
      "\n",
      "    # More methods can be implemented here as needed\n",
      "\n",
      "```\n",
      "Keep in mind that you must provide a proper auth token and handle OAuth2 token retrieval based on your specific authentication scheme. Furthermore, this is just a starting structure that will need completion and adjustments according to your application details.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(model, tokenizer, instruction, device)\n",
    "\n",
    "print(f'Generated response: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoZGPdVaTvYI",
    "outputId": "58a07cef-f064-49e2-ca6f-d0b1d3707c04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'I need your help to construct a PowerShell script with a function named \\'Get-CMSLogonUser\\' that fetches a list of current logon users from a Citrix management platform. I require the function to have optional input parameters: an identifier and a filter, along with several output parameters like page size, page number, all defaulting to 50 and 1 respectively. There also should be an \\'Auth\\' object that I\\'ll pass to it.\\n\\nThe function needs to use an API call to obtain the user list, which involves constructing the URL with the required parameters and performing an API request. It should handle the response and output the data.\\n\\nCould you improve this initial outline of the script?\\n\\n```powershell\\nfunction Get-CMSLogonUser {\\n    param (\\n        [int]$Identifier = 0,\\n        [string]$Filter = \"\",\\n        [int]$PageSize = 50,\\n        [int]$PageNumber = 1\\n    )\\n\\n    # Assuming $authObject exists and contains necessary auth info\\n\\n    $url = \"/api/v1/citrix/vnp/users/search?filter=$Filter&pageSize=$PageSize&pageNumber=$PageNumber&identifier=$Identifier\"\\n    # API call should be made here using $authObject\\n    # Response should be returned and processed\\n}\\n```',\n",
       "  'response': ' Understood. Here is a snippet of the refactored Python class incorporating the changes:\\n\\n```python\\nimport requests\\nfrom enum import Enum\\n\\nclass PageSize(Enum):\\n    FIRST = 1\\n    DEFAULT = 50\\n    LAST = 100\\n\\nclass PageNumber(Enum):\\n    FIRST = 1\\n\\nclass AuthError(Exception):\\n    pass\\n\\nclass CMSResponse:\\n    def __init__(self, status_code, data):\\n        self.status_code = status_code\\n        self.data = data\\n\\nclass CMSAuth:\\n    def __init__(self, client_id, client_secret):\\n        self.client_id = client_id\\n        self.client_secret = client_secret\\n        # Additional security-related fields could be added here\\n\\n    def perform_api_call(self, auth_token, payload):\\n        # Example of OAuth2 request - this may vary to fit exact OAuth2 setup\\n        headers = {\\'Authorization\\': f\\'Bearer {auth_token}\\'}\\n        url = \\'https://api.example.com/citrix\\'\\n        response = requests.post(url, json=payload, headers=headers)\\n        if response.status_code != 200:\\n            raise AuthError(f\"Auth failed with status code: {response.status_code}\")\\n        return response.json()\\n\\nclass LogonUserRetriever:\\n    def __init__(self, auth):\\n        self.auth = auth\\n\\n    def _get_data(self, filter, identifier, page_size=PageSize.DEFAULT.value, page_number=PageNumber.FIRST.value):\\n        payload = {\\n            \\'filter\\': filter,\\n            \\'pageSize\\': page_size,\\n            \\'pageNumber\\': page_number,\\n            \\'identifier\\': identifier\\n        }\\n        return self.auth.perform_api_call(auth_token=\"YOUR_AUTH_TOKEN_HERE\", payload=payload)\\n\\n    def get_logon_users(self, filter=\\'\\', identifier=0):\\n        if not filter:\\n            raise ValueError(\"Filter must be provided\")\\n        result = self._get_data(filter=filter, identifier=identifier)\\n        return result\\n\\n    # More methods can be implemented here as needed\\n\\n```\\nKeep in mind that you must provide a proper auth token and handle OAuth2 token retrieval based on your specific authentication scheme. Furthermore, this is just a starting structure that will need completion and adjustments according to your application details.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [\n",
    "    {'instruction': instruction, 'response': response}\n",
    "]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PHF4FW4VLYZ"
   },
   "source": [
    "# Combine 2 steps to create an instruction dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NjF5Hg-U-EF",
    "outputId": "c80fbf53-0142-4806-a873-93998b77b2d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:28<00:00, 49.38s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "dataset_size = 3\n",
    "\n",
    "for _ in trange(dataset_size):\n",
    "    instruction = generate_instruction(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        pre_query_template='<s><|user|>',\n",
    "        stopping_criteria=stopping_criteria,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    response = generate_response(model, tokenizer, instruction, device)\n",
    "\n",
    "    entry = {\n",
    "        'instruction': instruction,\n",
    "        'response': response\n",
    "    }\n",
    "\n",
    "    dataset.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UWYy6EcDWJ3D"
   },
   "outputs": [],
   "source": [
    "with open(\"instruction-data-phi3.json\", mode=\"w\") as file:\n",
    "    json.dump(dataset, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91SieYg9YI05",
    "outputId": "356680ab-635b-4933-c23a-e0a697cf0786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Hello! Can you provide a detailed account of the historical event where the Treaty of Versailles was signed after World War I? Make sure to mention the key figures involved, the countries that were part of the negotiation, the date of signing, and the impact it had on international relations. Give a comprehensive answer without missing any crucial details.',\n",
       "  'response': ' Certainly! The Treaty of Versailles was a historically significant event as it marked the official end of World War I. It was signed on June 28, 1919, exactly five years after the assassination of Archduke Franz Ferdinand, which was one of the triggers for World War I. \\n\\nThe peace conference for the treaty took place in the Palace of Versailles, France, hence its name. The main figures involved in the negotiation of the treaty were Georges Clemenceau, the French Prime Minister, David Lloyd George, the British Prime Minister, and Woodrow Wilson, the President of the United States. These three leaders, known as the \"Big Three,\" made up the Council of the League of Nations which primarily worked on forming the treaty. Other influential leaders included Vittorio Orlando, the Italian Prime Minister, and Max von Baden, the German Chancellor.\\n\\nThe negotiations were indeed tumultuous and fraught with tension due to differences in each country\\'s perspective on the conflict\\'s resolution. The Big Three held opposing positions. Clemenceau wanted to cripple Germany, hence imposing heavy penalties. Wilson proposed his Fourteen Points as a framework for peace, seeking fair treatment for Germany, while Britain under Lloyd George aimed for a balance between the two extremes.\\n\\nThe Treaty, comprising 440 articles and over half a million words, held Germany responsible for the beginning and the continuation of the war. They were forced to disarm, make substantial financial reparations, and accept territorial losses through the Redrawing of Europe\\'s map, which led to Germany losing territory including Alsace-Lorraine to France and significant parts of western Germany to Belgium.\\n\\nIn addition, reparations were indeed demanding. The figure was set at 132 billion gold marks (later reduced to 50 billion), a sum which strained the already weakening economy of Germany and led to severe economic hardships for many citizens.\\n\\nThe Treaty also included the establishment of the League of Nations, an international diplomatic group designed to maintain world peace. However, the Treaty was met with various reactions. Germany saw it as a \"Diktat\" or a forced peace and was deeply resentful of the severe terms. The signing of the Treaty sparked widespread anti-war and peace sentiment in Germany, contributing to its political instability in the years that followed.\\n\\nIn the international arena, the Treaty has been subject to significant criticism. Historians argue that the severe conditions imposed on Germany contributed to economic hardship and political instability, thereby setting the stage for World War II. Some also argue that the League of Nations, despite its intentions, was unable to prevent future conflicts due to its lack of enforcement power.\\n\\nNonetheless, the Treaty of Versailles marks a crucial chapter in world history. It illustrates the difficulties in reaching a consensus after a world war and the long-lasting implications of how such treaties are agreed upon and enforced. Despite its flaws, it also showed an early effort to establish a global institution to maintain peace, which led to the creation of the United Nations after World War II.'},\n",
       " {'instruction': \"Hey, I need some SQL queries for a 'users' table. Get me the first 10 users sorted alphabetically by 'username'. Then give me all where the age is under 20. List the users who signed up last month, including their email addresses, sorted by signup time descending. Another query to find users over 18, again sorted by signup time descending. Retrieve the top 5 users by age. Finally, give me the oldest users sorted alphabetically by name. Comments would be great for each query.\",\n",
       "  'response': ' Absolutely, here\\'s how you can create a reusable Python function to perform these queries with parameters for age and month:\\n\\n```python\\n# Start of the Python script for context\\nimport psycopg2\\n\\ndef fetch_users(age_threshold=None, signup_month=None):\\n    try:\\n        connection = psycopg2.connect(user=\"your_username\", password=\"your_password\", host=\"your_host\", port=\"your_port\", database=\"your_database\")\\n        cursor = connection.cursor()\\n        \\n        # Query to get users below certain age\\n        if age_threshold:\\n            cursor.execute(\"\"\"\\n            SELECT id, name, age FROM users\\n            WHERE age < %s ORDER BY age ASC;\\n            \"\"\", (age_threshold,))\\n        # Other queries with conditional logic here...\\n    except (Exception, psycopg2.Error) as error:\\n        print(\"Error while connecting to PostgreSQL\", error)\\n    finally:\\n        # Closing database connection\\n        if connection:\\n            cursor.close()\\n            connection.close()\\n            print(\"PostgreSQL connection is closed\")\\n            \\n# End of the reusable function and the script\\n\\n# Usage example for getting users under 20 and signup in the last month:\\n# fetch_users(20, \\'True\\')  # The signup_month parameter is controlled by the psycopg2 library and passed as a string \\'True\\'/\\'False\\'.\\n```\\n\\nThis snippet has encapsulated the database querying within the `fetch_users` Python function, allowing you to pass the desired parameters to fetch specific subsets of the users\\' data. Remember to replace the placeholder values with your actual database credentials. The `signup_month` is passed as a string (\\'True\\' or \\'False\\') to the PostgreSQL function because psycopg2 does not directly translate boolean values in parameterized queries. You would need to handle this conversion inside the query logic if required.'},\n",
       " {'instruction': '- Create a React component for a customizable list item in a UI.\\n\\n- Use React and class components; import the `withStyles` HOC and `PureComponent` from `react-addons-pure-renderers`.\\n\\n- PropTypes should: `mode` (boolean), `iconName` (string), `name` (string), `value` (number), `disabled` (boolean, default false), `onChange` (function).\\n\\n- Style should be based on `withStyles`.\\n\\n- Include a method `renderValue` for number to formatted string conversion, and a helper to format with a unit.\\n\\n- Include a `renderButton` method for rendering a button if allowed.\\n\\n- The button should have no onClick handler but conditionally render based on the `disabled` prop.\\n\\n- Render an icon, name, and value or formatted value. If `disabled`, render only the icon and name.\\n\\n- Have defaults for non-provided props using `defaults`.\\n\\n- Export this component as default.',\n",
       "  'response': ' Absolutely, here are the refactorings with the suggested improvements:\\n\\n```javascript\\n// ... (previous imports)\\n\\nclass ListItem extends React.PureComponent<ListItemProps, {}> {\\n  // ... (rest of the class stays unchanged)\\n\\n  // Refactored renderValue to always return a string\\n  renderValue(value: number) {\\n    return `$${this.formatValue(value)}`;\\n  }\\n\\n  // Updated onButtonPressHandler to handle both single press and long press\\n  onButtonPressHandler(e: React.MouseEvent) {\\n    if (this.props.onChange) {\\n      this.props.onChange(this.props.value);\\n    }\\n    e.preventDefault();\\n  }\\n\\n  // Optimized renderButton using \\'&&\\' operator\\n  renderButton() {\\n    return this.props.disabled && \\'\\' || (\\n      <Button\\n        htmlFor=\"listItemButton\"\\n        disabled={this.props.disabled}\\n        // Assume \\'handlePress\\' is a method to be created/passed down for additional functionality\\n        onClick={this.onButtonPressHandler}\\n      >\\n        {/* Label or other content for the button */}\\n      </Button>\\n    );\\n  }\\n\\n  // ... (the rest of the class remains the same)\\n}\\n\\n// ... (rest of the component code remains unchanged)\\n```\\n\\nRemember to include any additional props you might be needing for the button press handlers, such as `handlePress`, and to define it if it doesn\\'t exist.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IUZsKgXiZe13"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "scratchpad",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f52bb95d9b44033a984205adc69b2a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d4a782358af4a2abdf677aa404a9831": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f8ef86f775643ef9ff60e11a82d7994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "535b15377b3a44f1846b29ae9391e0ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d2d17c166d484198e8f1b109c3de33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9eb4878622cc4162b8e590be415c28be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af873eddff054a62b6cae6c16212cb61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f8ef86f775643ef9ff60e11a82d7994",
      "placeholder": "​",
      "style": "IPY_MODEL_9eb4878622cc4162b8e590be415c28be",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "d16c92d8e2eb465292ad69f8ad0cb6be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_535b15377b3a44f1846b29ae9391e0ac",
      "placeholder": "​",
      "style": "IPY_MODEL_99d2d17c166d484198e8f1b109c3de33",
      "value": " 2/2 [00:41&lt;00:00, 19.50s/it]"
     }
    },
    "e095a60c04e44fe1a389c5231cbb5acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af873eddff054a62b6cae6c16212cb61",
       "IPY_MODEL_e4ac157ccbea408a9280b8621200b1a5",
       "IPY_MODEL_d16c92d8e2eb465292ad69f8ad0cb6be"
      ],
      "layout": "IPY_MODEL_f8e6ae664a98459f94704cc6a0495338"
     }
    },
    "e4ac157ccbea408a9280b8621200b1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f52bb95d9b44033a984205adc69b2a9",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d4a782358af4a2abdf677aa404a9831",
      "value": 2
     }
    },
    "f8e6ae664a98459f94704cc6a0495338": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
